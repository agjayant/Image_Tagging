{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ranking import *\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge as KR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Can change NuSVR to other types\n",
    "#Matrix regression\n",
    "from sklearn.svm import NuSVR as SVR\n",
    "class kernel_svm:\n",
    "    def __init__(self):\n",
    "        self.x=0\n",
    "        self.y=0\n",
    "        self.s=0\n",
    "        self.x_par=0 #Number of x parameters\n",
    "        self.y_par=0 #Number of x parameters\n",
    "        \n",
    "    def fit(self,x,y,kernel='linear',C=1e3,gamma=0.1,degree=2,coef0=1):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.x_par = x.shape[1]\n",
    "        try:\n",
    "            self.y_par = y.shape[1] \n",
    "        except:\n",
    "            self.y_par = 1\n",
    "                \n",
    "        self.s = [ SVR(kernel=kernel, C=C, gamma=gamma, degree=degree, coef0=coef0)] * self.y_par\n",
    "        for i in range(0, self.y_par):\n",
    "            if self.y_par == 1:\n",
    "                self.s[i].fit(x,y)\n",
    "            else:\n",
    "                self.s[i].fit(x, y[:,i])\n",
    "    \n",
    "    def predict(self,x):\n",
    "        y = np.zeros([len(x), self.y_par])\n",
    "        for i in range(0, self.y_par):\n",
    "            y[:,i] = self.s[i].predict(x)\n",
    "        return y\n",
    "    \n",
    "    def error(self,y1,y2):\n",
    "        return 1.0/y1.size * np.linalg.norm(y1-y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MSE(a,b):\n",
    "    mse =0.0\n",
    "    print(a.shape, b.shape)\n",
    "    if a.shape != b.shape:\n",
    "        print(\"Size of vector mixmatch - cannot calculate Mean Squared error\")\n",
    "    for i in range(0,len(a)):\n",
    "        mse += np.linalg.norm(b[i] - a[i])**2\n",
    "    mse = 1.0/len(a)*mse\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluation metric\n",
    "def F1_score(tags_pred, tags_actual,k1=3, k2=5):\n",
    "    k1_count=0.0\n",
    "    k2_count=0.0\n",
    "    for i in range(0,k1):\n",
    "        if tags_actual[tags_pred[i]] == 1:\n",
    "            k1_count += 1\n",
    "\n",
    "    for i in range(0,k2):\n",
    "        if tags_actual[tags_pred[i]] == 1:\n",
    "            k2_count += 1\n",
    "\n",
    "    num_tags = 1.0*(len(tag_word_vectors) + sum(tags_actual ))/2\n",
    "    \n",
    "    k1_recall = 1.0*k1_count/num_tags\n",
    "    k2_recall = 1.0*k2_count/num_tags \n",
    "    k1_precision = k1_count/k1\n",
    "    k2_precision = k2_count/k2\n",
    "    \n",
    "    tmp1 = 2.0*k1_precision*k1_recall/(k1_precision + k1_recall)\n",
    "    tmp2 = 2.0*k2_precision*k2_recall/(k2_precision+k2_recall)\n",
    "    if tmp1 >= 0 and tmp2 >= 0:\n",
    "        return [tmp1,tmp2]\n",
    "    elif tmp1 >= 0:\n",
    "        return [tmp1,0]\n",
    "    elif tmp2 >= 0:\n",
    "        return [0,tmp2]\n",
    "    else:\n",
    "        return [0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadData(wvToUse = 'original'):\n",
    "    print(\"Loading Data\")\n",
    "    global training_data, training_label, valid_data, valid_label, testing_data, testing_label\n",
    "    global n_training, n_testing, n_valid\n",
    "    global w_list, tag_word_vectors, len_tag_wv\n",
    "    \n",
    "    f = h5py.File('l2_normalized_semantic_SVM_full_data_with_val_291labels_no_zero.mat' )\n",
    "    training_data = np.transpose(f[\"prepared_training_data\"])\n",
    "    training_label = np.transpose(f[\"prepared_training_label\"])\n",
    "    valid_data = np.transpose(f[\"prepared_val_data\"])\n",
    "    valid_label = np.transpose(f[\"prepared_val_label\"])\n",
    "    testing_data = np.transpose(f[\"prepared_testing_data\"])\n",
    "    testing_label = np.transpose(f[\"prepared_testing_label\"])\n",
    "    \n",
    "    n_training = len(training_data)\n",
    "    n_valid = len(valid_data)\n",
    "    n_testing = len(testing_data)\n",
    "\n",
    "    if wvToUse == 'original':\n",
    "        tag_word_vectors = np.transpose(h5py.File('291labels.mat')[\"semantic_mat\"])\n",
    "    elif wvToUse == 'embeddings':\n",
    "        tag_word_vectors = scipy.io.loadmat('embeddings.mat')[\"U\"]\n",
    "\n",
    "    len_tag_wv =tag_word_vectors.shape[1]\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return training_data, training_label, valid_data, valid_label, testing_data, testing_label, n_training, n_testing, n_valid, tag_word_vectors, len_tag_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modifyData(n_training_local=0, n_testing_local=0, n_valid_local=0):\n",
    "    if n_training == 0 or n_testing == 0 or n_valid == 0:\n",
    "        print(\"0 value entries not allowed\")\n",
    "    \n",
    "    global training_data, training_label, valid_data, valid_label, testing_data, testing_label\n",
    "    global n_training, n_testing, n_valid\n",
    "    global w_list\n",
    "    \n",
    "    if n_training_local != 0:\n",
    "        try:\n",
    "            training_data = training_data[0:n_training_local]\n",
    "            training_label = training_label[0:n_training_local]\n",
    "        except:\n",
    "            print('index (n_training) out of range, ignoring n_training for training')\n",
    "            \n",
    "        try:\n",
    "            valid_data = valid_data[0:n_valid_local]\n",
    "            valid_label = valid_label[0:n_valid_local]\n",
    "        except:\n",
    "            print('index (n_testing) out of range, ignoring n_testing for validation')\n",
    "            \n",
    "        try:\n",
    "            testing_data = testing_data[0:n_testing_local]\n",
    "            testing_label = testing_label[0:n_testing_local]\n",
    "        except:\n",
    "            print('index (n_valid) out of range, ignoring n_valid for test')\n",
    "    n_training = len(training_data)\n",
    "    n_valid = len(valid_data)\n",
    "    n_testing = len(testing_data)\n",
    "\n",
    "    #tag_word_vectors = np.transpose(h5py.File('291labels.mat')[\"semantic_mat\"])\n",
    "\n",
    "    print(\"Done\")\n",
    "    return training_data, training_label, valid_data, valid_label, testing_data, testing_label, n_training, n_testing, n_valid#, tag_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rankSVM():\n",
    "    global w_list\n",
    "    print(\"Ranking SVM for Training Data\")\n",
    "    r=RankSVM()\n",
    "    w_list=np.zeros([n_training,len_tag_wv])\n",
    "    for i in range(0,len(training_data)):\n",
    "        r.fit(tag_word_vectors,training_label[i])\n",
    "        w_list[i] = r.coef_\n",
    "    print('Done')\n",
    "    return w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fitLinearRegression():\n",
    "    global A\n",
    "    print(\"Fitting Linear Regression model\")\n",
    "    lin_reg = LinearRegression(normalize=True)\n",
    "    lin_reg.fit(training_data, w_list)\n",
    "    print(lin_reg.score(training_data, w_list))\n",
    "    A = lin_reg.coef_\n",
    "    #print(w_list.shape,\" = \", A.shape, training_data.shape)\n",
    "    print(\"Done\")\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fitKernelRegression(method = 'ridge', kernel = 'poly'):\n",
    "    global s\n",
    "    \n",
    "    print(\"Fitting Support Vector Kernelized Regression model : \" + method + \" ; Kernel : \" + kernel)\n",
    "    \n",
    "    if method == 'ridge':\n",
    "        s=KR(kernel='poly',degree=100000)\n",
    "        s.fit(training_data,w_list)\n",
    "        print(\"Ridge training score : \" + str(s.score(training_data,w_list)) + \" ... 1 best possible, <0 very bad\")\n",
    "    elif method == 'SVR':\n",
    "        s = kernel_svm()\n",
    "        s.fit(training_data, w_list,'poly',C=875,gamma=0.0001,degree=1,coef0=1)\n",
    "        #w = s.predict(training_data)\n",
    "        #print(s.error(w, w_list))\n",
    "    print(\"Done\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printAccuracies(fitType = 'lin', n1 = 10, n2 = 10, n3 = 10): #fitType = linear/kernelized\n",
    "    if fitType != 'lin' and fitType != 'kernel':\n",
    "        print('Invalid fitType, fitType should be lin or kernel')\n",
    "        return\n",
    "    #Accuracy for Training Data\n",
    "    #r=RankSVM()\n",
    "    avg1 = 0\n",
    "    avg2 = 0\n",
    "\n",
    "    for i in range(0,n1):\n",
    "        j=int(np.floor(np.random.rand(1)*n_training))\n",
    "        if fitType == 'lin':#Linear Regression\n",
    "            w = np.dot(training_data[j], np.transpose(A))\n",
    "        else:#Kernelized Support vector Regression\n",
    "            w = s.predict([training_data[j]]).reshape((len_tag_wv,))\n",
    "            \n",
    "        tags_pred_score = np.dot(w,np.transpose(tag_word_vectors))\n",
    "        tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "        tag_pred_ranked.reverse()\n",
    "        \n",
    "        [tmp1, tmp2] = F1_score(tag_pred_ranked, training_label[j],3,5)\n",
    "        #print('TRAINING : ' + str(tmp1) + \" : \" + str(tmp2))\n",
    "        avg1 += tmp1\n",
    "        avg2 += tmp2\n",
    "    \n",
    "    print(\"TRAIN : \" + str(avg1/n1) + \" : \"+ str(avg2/n1))\n",
    "\n",
    "    #Accuracy for Validation Data\n",
    "    avg1 =0 \n",
    "    avg2 = 0\n",
    "    for i in range(0,n2):\n",
    "        j=int(np.floor(np.random.rand(1)*n_valid))\n",
    "        if fitType == 'lin': #Linear Regression\n",
    "            w = np.dot(valid_data[j], np.transpose(A))\n",
    "        else:  #Kernelized Support vector/Ridge Regression\n",
    "            w = s.predict([valid_data[j]]).reshape((len_tag_wv,))\n",
    "         \n",
    "        #w = np.dot(valid_data[j], np.transpose(A))\n",
    "        tags_pred_score = np.dot(w,np.transpose(tag_word_vectors)) \n",
    "        tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "        tag_pred_ranked.reverse()\n",
    "\n",
    "        [tmp1, tmp2] = F1_score(tag_pred_ranked, valid_label[j],3,5)\n",
    "\n",
    "        avg1 += tmp1\n",
    "        avg2 += tmp2\n",
    "\n",
    "    print(\"VALID : \" + str(avg1/n2) + \" : \"+ str(avg2/n2))\n",
    "    \n",
    "    #Accuracy for Testing Data\n",
    "    avg1 =0 \n",
    "    avg2 = 0\n",
    "    for i in range(0,n3):\n",
    "        j=int(np.floor(np.random.rand(1)*n_testing))\n",
    "        if fitType == 'lin':#Linear Regression\n",
    "            w = np.dot(testing_data[j], np.transpose(A))\n",
    "        else:#Kernelized Support vector Regression\n",
    "            w = s.predict([testing_data[j]]).reshape((len_tag_wv,))\n",
    "         \n",
    "        tags_pred_score = np.dot(w,np.transpose(tag_word_vectors)) \n",
    "        tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "        tag_pred_ranked.reverse()\n",
    "\n",
    "        [tmp1, tmp2] = F1_score(tag_pred_ranked, testing_label[j],3,5)\n",
    "        #print(\"TESTING : \" + str(tmp1) + \" : \" + str(tmp2))\n",
    "        avg1 += tmp1\n",
    "        avg2 += tmp2\n",
    "\n",
    "    print(\" TEST : \" + str(avg1/n3) + \" : \"+ str(avg2/n3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "loadData('embeddings');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#modifyData(2000,2000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking SVM for Training Data\n"
     ]
    }
   ],
   "source": [
    "rankSVM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Linear Regression model\n",
      "0.998888996534\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -1.61760430e+11,  -6.45031370e+11,  -5.00466876e+11, ...,\n",
       "         -9.79619584e+10,   7.13386145e+10,   6.53986210e+10],\n",
       "       [ -7.08362835e+09,  -2.82464784e+10,  -2.19158749e+10, ...,\n",
       "         -4.28983839e+09,   3.12397928e+09,   2.86386186e+09],\n",
       "       [  6.18577950e+10,   2.46662414e+11,   1.91380410e+11, ...,\n",
       "          3.74610202e+10,  -2.72801536e+10,  -2.50086779e+10],\n",
       "       ..., \n",
       "       [  4.49802978e+10,   1.79362178e+11,   1.39163509e+11, ...,\n",
       "          2.72400243e+10,  -1.98369411e+10,  -1.81852227e+10],\n",
       "       [ -7.84428178e+10,  -3.12796387e+11,  -2.42692431e+11, ...,\n",
       "         -4.75048937e+10,   3.45943809e+10,   3.17138877e+10],\n",
       "       [ -1.25221885e+10,  -4.99331289e+10,  -3.87421112e+10, ...,\n",
       "         -7.58342512e+09,   5.52246047e+09,   5.06263406e+09]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Support Vector Kernelized Regression model : ridge ; Kernel : poly\n",
      "Ridge training score : 0.998889166257 ... 1 best possible, <0 very bad\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=1, coef0=1, degree=100000, gamma=None, kernel='poly',\n",
       "      kernel_params=None)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitKernelRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "LINEAR\n",
      "TRAIN : 0.014 : 0.024\n",
      "VALID : 0.0426558441558 : 0.0555140692641\n",
      " TEST : 0.0523006715507 : 0.0542828282828\n",
      "\n",
      "--------------------------------------\n",
      "KERNEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN : 0.426356809857 : 0.449933674169\n",
      "VALID : 0.120427072927 : 0.111867549118\n",
      " TEST : 0.11527028527 : 0.123357436681\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------\\nLINEAR')\n",
    "printAccuracies('lin',100,100,100)\n",
    "print('\\n--------------------------------------\\nKERNEL')\n",
    "printAccuracies('kernel',100,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = {}\n",
    "model['tag_word_vectors'] = tag_word_vectors\n",
    "model['linear_model'] = A\n",
    "model['kernel_model'] = s\n",
    "modelFile = open('model.pkl', \"w\")\n",
    "pickle.dump(model,modelFile)\n",
    "w_list = pickle.load(open('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "291\n",
      "((300,), (300, 4096))\n"
     ]
    }
   ],
   "source": [
    "print(tag_word_vectors.shape[1])\n",
    "print(len(tag_pred_ranked))\n",
    "print(w.shape,A.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
