{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushab/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ranking import *\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(a,b):\n",
    "    mse =0.0\n",
    "    print(a.shape, b.shape)\n",
    "    if a.shape != b.shape:\n",
    "        print(\"Size of vector mixmatch - cannot calculate Mean Squared error\")\n",
    "    for i in range(0,len(a)):\n",
    "        mse += np.linalg.norm(b[i] - a[i])**2\n",
    "    mse = 1.0/len(a)*mse\n",
    "    return mse\n",
    "\n",
    "f = h5py.File('l2_normalized_semantic_SVM_full_data_with_val_291labels_no_zero.mat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F1_score(tags_pred, tags_actual,k1=3, k2=5):\n",
    "    k1_count=0.0\n",
    "    k2_count=0.0\n",
    "    for i in range(0,k1):\n",
    "        if tags_actual[tags_pred[i]] == 1:\n",
    "            k1_count += 1\n",
    "\n",
    "    for i in range(0,k2):\n",
    "        if tags_actual[tags_pred[i]] == 1:\n",
    "            k2_count += 1\n",
    "\n",
    "    num_tags = 1.0*(len(tag_word_vectors) + sum(tags_actual ))/2\n",
    "    \n",
    "    k1_recall = 1.0*k1_count/num_tags\n",
    "    k2_recall = 1.0*k2_count/num_tags \n",
    "    k1_precision = k1_count/k1\n",
    "    k2_precision = k2_count/k2\n",
    "    \n",
    "    tmp1 = 2.0*k1_precision*k1_recall/(k1_precision + k1_recall)\n",
    "    tmp2 = 2.0*k2_precision*k2_recall/(k2_precision+k2_recall)\n",
    "    if tmp1 >= 0 and tmp2 >= 0:\n",
    "        return [tmp1,tmp2]\n",
    "    elif tmp1 >= 0:\n",
    "        return [tmp1,0]\n",
    "    elif tmp2 >= 0:\n",
    "        return [0,tmp2]\n",
    "    else:\n",
    "        return [0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Loading Data\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"-----------------------------------------\\nLoading Data\")\n",
    "n_all = 1000\n",
    "\n",
    "training_data = np.transpose(f[\"prepared_training_data\"])\n",
    "training_label = np.transpose(f[\"prepared_training_label\"])\n",
    "valid_data = np.transpose(f[\"prepared_val_data\"])\n",
    "valid_label = np.transpose(f[\"prepared_val_label\"])\n",
    "testing_data = np.transpose(f[\"prepared_testing_data\"])\n",
    "testing_label = np.transpose(f[\"prepared_testing_label\"])\n",
    "\n",
    "n_training = len(training_data)\n",
    "n_valid = len(valid_data)\n",
    "n_testing = len(testing_data)\n",
    "\n",
    "tag_word_vectors = np.transpose(h5py.File('291labels.mat')[\"semantic_mat\"])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking SVM for Training Data\n"
     ]
    }
   ],
   "source": [
    "print(\"Ranking SVM for Training Data\")\n",
    "r=RankSVM()\n",
    "w_list=np.zeros([n_training,300])\n",
    "for i in range(0,len(training_data)):\n",
    "    r.fit(tag_word_vectors,training_label[i])\n",
    "    w_list[i] = r.coef_\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Fitting Linear Regression model\")\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(training_data, w_list)\n",
    "print(lin_reg.score(training_data, w_list))\n",
    "A = lin_reg.coef_\n",
    "print(w_list.shape,\" = \", A.shape, training_data.shape)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Fitting Support Vector Kernelized Regression model\")\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "#y_rbf = svr_rbf.fit(training_data, w_list)\n",
    "y_lin = svr_lin.fit(training_data, w_list)\n",
    "y_poly = svr_poly.fit(training_data, w_list)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking SVM for Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages : 0.506236493471 : 0.543220654681\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Training Data\")\n",
    "r=RankSVM()\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "\n",
    "for j in range(0,n_training):\n",
    "    w = np.dot(training_data[j], np.transpose(A))\n",
    "    tags_pred_score = np.dot(w,np.transpose(tag_word_vectors))\n",
    "\n",
    "    tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "    tag_pred_ranked.reverse()\n",
    "    [tmp1, tmp2] = F1_score(tag_pred_ranked, training_label[j],3,5)\n",
    "    \n",
    "    avg1 += tmp1\n",
    "    avg2 += tmp2\n",
    "\n",
    "print(\"Averages : \" + str(avg1/n_training) + \" : \"+ str(avg2/n_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking SVM for Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages : 0.283574736374 : 0.301731812447\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Testing Data\")\n",
    "avg1 =0 \n",
    "avg2 = 0\n",
    "for j in range(0,n_testing):\n",
    "    w = np.dot(testing_data[j], np.transpose(A))\n",
    "    tags_pred_score = np.dot(w,np.transpose(tag_word_vectors)) \n",
    "    tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "    tag_pred_ranked.reverse()\n",
    "    \n",
    "    [tmp1, tmp2] = F1_score(tag_pred_ranked, testing_label[j],3,5)\n",
    "    \n",
    "    avg1 += tmp1\n",
    "    avg2 += tmp2\n",
    "\n",
    "print(\"Averages : \" + str(avg1/n_testing) + \" : \"+ str(avg2/n_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking SVM for Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages : 0.277139618367 : 0.29699567689\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Validation Data\")\n",
    "avg1 =0 \n",
    "avg2 = 0\n",
    "for j in range(0,n_valid):\n",
    "    w = np.dot(valid_data[j], np.transpose(A))\n",
    "    tags_pred_score = np.dot(w,np.transpose(tag_word_vectors)) \n",
    "    tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "    tag_pred_ranked.reverse()\n",
    "    \n",
    "    [tmp1, tmp2] = F1_score(tag_pred_ranked, valid_label[j],3,5)\n",
    "    \n",
    "    avg1 += tmp1\n",
    "    avg2 += tmp2\n",
    "\n",
    "print(\"Averages : \" + str(avg1/n_valid) + \" : \"+ str(avg2/n_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy for Testing Data with Kernelized SVR rbf\")\n",
    "avg1 =0 \n",
    "avg2 = 0\n",
    "for j in range(0,n_testing):\n",
    "    w = svr_rbf(testing_data[j])\n",
    "    tags_pred_score = np.dot(w,np.transpose(tag_word_vectors)) \n",
    "    tag_pred_ranked = [i[0] for i in sorted(enumerate(tags_pred_score), key=lambda x:x[1])]\n",
    "    tag_pred_ranked.reverse()\n",
    "    \n",
    "    [tmp1, tmp2] = F1_score(tag_pred_ranked, testing_label[j],3,5)\n",
    "    \n",
    "    avg1 += tmp1\n",
    "    avg2 += tmp2\n",
    "\n",
    "print(\"Averages : \" + str(avg1/n_testing) + \" : \"+ str(avg2/n_testing))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
