#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Wed Sep  7 15:39:32 2016

@author: Yang Zhang

This file containg the objective functions of non-linear tags ranking NN
"""
import h5py,numpy as np
import theano.tensor as T
from theano import scan


semantic_mat_r=h5py.File('291labels.mat','r')
semantic_mat=semantic_mat_r.get('semantic_mat')
semantic_mat=np.array(semantic_mat).astype("float32")
"""
#This semantic mat matrix contains the word embedding matrix.
Replace with whatever embedding matrix you like if you would like to test it on other dataset
"""


"""
rank_layer: get label confidence by multiply ingsemtantic embeddings with principle direction generated by previous layers
"""
def rank_layer(input_tensor):
    label_predict=T.dot(input_tensor,semantic_mat)
    return label_predict
    
"""
define the ranknet loss function used to train the nerual network.
You have two choice:
    
1, semantic_RankNet_mean: Regular objective function. Runs fast when there are less labels (<1000).
However its computational cost is n^2 where n is the training labels number.

2, semantic_RankNet_mean_memo_eff: A memory efficient version of the first objective function. Runs relatively slower
with few labels but much faster if you have a lot of labels.

They took the same input and output the same loos. The only difference is the implementation.
Refer to the main code to see how to use them to train a nerual netowkr
    
"""
def RankNet(y_true, y_pred):
    positive_tags=T.clip(y_true,0.,1.)
    negative_tags=T.clip(-y_true,0.,1.)
    positive_tags_per_im=positive_tags.sum()
    negative_tags_per_im=negative_tags.sum()
    weight_per_image=positive_tags_per_im*negative_tags_per_im
    
    positive_tag_conf=y_pred[positive_tags.nonzero()].dimshuffle('x',0)
    negative_tag_conf=y_pred[negative_tags.nonzero()].dimshuffle(0,'x')
    
    score_matrix=negative_tag_conf-positive_tag_conf
    
    return T.log(1.+T.exp(score_matrix)).mean()/weight_per_image



def semantic_RankNet_mean_memo_eff(Y_true, Y_pred):
    image_scores, updates =  scan(fn=RankNet,
                                  outputs_info=None,
                                  sequences=[Y_true, Y_pred])
    return image_scores.mean()


def semantic_RankNet_mean(y_true, y_pred):
    Input_shape=y_true.shape
    
    # weights
    positive_tags=T.clip(y_true,0.,1.)
    negative_tags=T.clip(-y_true,0.,1.)
    positive_tags_per_im=positive_tags.sum(axis=1)
    negative_tags_per_im=negative_tags.sum(axis=1)
    weight_per_image=positive_tags_per_im*negative_tags_per_im
    weight_per_image=T.reshape(weight_per_image,(Input_shape[0],1,1))
    
    pos_socre_mat=y_pred*positive_tags
    neg_socre_mat=y_pred*negative_tags
    
    IW_pos3=T.reshape(pos_socre_mat,(Input_shape[0],1,Input_shape[1]))
    IW_neg3=T.reshape(neg_socre_mat,(Input_shape[0],Input_shape[1],1))
    
    O=IW_neg3-IW_pos3
    
    return T.log(1.+T.exp(O)).sum(axis=1).sum(axis=1)/weight_per_image.mean()